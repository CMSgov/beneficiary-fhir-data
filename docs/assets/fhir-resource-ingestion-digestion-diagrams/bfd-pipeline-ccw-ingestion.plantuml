@startuml
title BFD-Pipeline-CCW Ingestion of Beneficiary/Claim Data Sequence
participant ccw
database s3
participant "bfd-pipeline"
participant splunk
note over splunk: Specific Splunk Components: \n forwarders/indexers/search heads/ui/configuration
participant slack
database "bfd-db"
ccw -> s3: Timestamped folder with: \n RIF files for a resource, manifest.xml \n placed in 'bfd-prod-etl' S3 bucket  
s3 -> s3: Timestamped folder moved to \n 'Incoming' folder of bucket
s3 -> "bfd-pipeline": New data discovered by pipeline and logged
"bfd-pipeline" -> splunk: Data discovery messages in pipeline logs made available for querying by splunk
splunk -> "bfd-pipeline": Splunk discovers new data from pipeline logs
"bfd-pipeline" --> splunk
splunk -> slack: Data discover status sent \n to #BFD-notices channel
slack --> "bfd-pipeline" 
"bfd-pipeline" -> "bfd-pipeline": ETL/RIF Loader process triggered
group ETL
"bfd-pipeline" -> "bfd-pipeline": datasetMonitorListener interface instantiated \n in CcwRifLoadJob class to manage ETL
"bfd-pipeline" -> "bfd-pipeline": ETL process parses manifest.xml file \n for specific resource data \n and checks for DB operation \n denoted  in manifest i.e. INSERT/UPDATE
"bfd-pipeline" -> "bfd-db": DB operations applied for resource \n based on column and rif layout fhir mappings
"bfd-db" --> "bfd-pipeline"
"bfd-pipeline" -> "bfd-pipeline": Process marked as 'complete' and load status is logged
end
"bfd-pipeline" -> splunk: Data load messages in pipeline logs made available for querying by splunk
splunk -> "bfd-pipeline": Splunk discovers new data load from pipeline logs
"bfd-pipeline" --> splunk
splunk -> slack: Load status sent \n to #BFD-notices channel
slack --> s3
s3 -> s3: Timestamped folder for resource moved \n from 'Incoming' to the 'Done' folder
s3 --> "bfd-pipeline": ETL process continues if more \n resources still in 'Incoming' folder
"bfd-pipeline" --> s3
s3--> ccw
@enduml
