---
- hosts: localhost
  name: AWS - Provision Resources and Instances
  connection: local
  gather_facts: false
  
  vars:
    # "Compute Optimized" with 4 vCPUs, 7.5 GB RAM, $0.209/hour
    ec2_instance_type: "c4.xlarge"
  
  tasks:
    
    - name: Local - whoami
      local_action: command whoami
      register: whoami

    - name: Create Local Results Directory 
      file:
        path: results
        state: directory

# TODO: Currently there is a single client and server specified in hosts.yml that
# is used for this test.  Eventually change to what is commented out below where 
# the ec2 instances are enumerated.

#    - name: EC2 - Provision Security Group 'ssh-all'
#      ec2_group:
#        name: ssh-all
#        description: Allows incoming traffic on port 22 (from all IPs).
#        region: "{{ region }}"
#        rules:
#          - proto: tcp
#            from_port: 22
#            to_port: 22
#            cidr_ip: 0.0.0.0/0
#        rules_egress:
#          - proto: all
#            cidr_ip: 0.0.0.0/0
#    
#    - name: EC2 - Provision 'bluebutton-stress' client
#      ec2:
#        key_name: "{{ ec2_key_name }}"
#        group:
#          - default
#          - ssh-all
#        instance_type: "{{ ec2_instance_type }}"
#        image: "{{ ami_id_ubuntu }}"
#        region: "{{ region }}"
#        wait: true
#        exact_count: 1
#        count_tag:
#          Name: bluebutton-stress-client
#          Application: "BlueButton"
#        instance_tags:
#          Name: bluebutton-stress-client
#          Application: "BlueButton"
#          CreatedBy: "{{ whoami.stdout }}"
#      register: ec2_client
#    
#    - name: EC2 - Provision 'bluebutton-stress' servers
#      ec2:
#        key_name: "{{ ec2_key_name }}"
#        group:
#          - default
#          - ssh-all
#        instance_type: "{{ ec2_instance_type }}"
#        image: "{{ ami_id_ubuntu }}"
#        region: "{{ region }}"
#        wait: true
#        # The default of 300s here wasn't cutting it for 8 servers.
#        wait_timeout: 600
#        exact_count: "{{ num_servers }}"
#        count_tag:
#          Name: bluebutton-stress-server
#          Application: "BlueButton"
#        instance_tags:
#          Name: bluebutton-stress-server
#          Application: "BlueButton"
#          CreatedBy: "{{ whoami.stdout }}"
#      register: ec2_servers
#    
#    - name: Create inventory group 'client'
#      add_host: 
#        hostname: "{{ item.public_ip }}"
#        groupname: client
#      with_items: ec2_client.instances
#
#    - name: Create inventory group 'servers'
#      add_host:
#        hostname: "{{ item.public_ip }}"
#        groupname: servers
#      with_items: ec2_servers.instances
#
#    - name: Wait for SSH to come up
#      wait_for:
#        host: "{{ item.public_dns_name }}"
#        port: 22
#        timeout: 320
#        state: started
#      with_flattened:
#        - ec2_client.instances
#        - ec2_servers.instances

- name: Configure roles common to all servers 
  hosts: client:servers
  become: True
  gather_facts: True
  environment: "{{proxy_env}}"
  roles:
    - common

- name: Configure roles specific to jmeter client instance
  hosts: client
  become: True
  gather_facts: True
  environment: "{{proxy_env}}"
  roles:
    - client 

- name: Configure roles specific to jmeter server instance(s)
  hosts: servers
  become: True
  gather_facts: True
  environment: "{{proxy_env}}"
  roles:
    - server 

- name: Launch JMeter servers
  hosts: servers
  become: True
  environment: "{{proxy_env}}"
  gather_facts: True
  
  tasks:
    - name: Launch JMeter Server in Background
      # The "JMeter Server" is what the distributed testing nodes run.
      shell: "( ( nohup {{ remote_jmeter_dir }}/bin/jmeter -s 
        -Djava.rmi.server.hostname={{ jmeter_server_ip }} 
        -Dserver.rmi.localport={{ jmeter_server_rmi_local_port }} 
        -Dserver_port={{ jmeter_server_port }} 
        -j {{ remote_test_dir }}/log-jmeter.txt
        &> /dev/null) & )" 

- name: Launch JMeter client and start tests
  hosts: client
  become: True
#  user: ubuntu
  environment: "{{proxy_env}}"
  gather_facts: True
  
  #vars:
    #serversyses: "{{ hostvars | get_members(groups, 'servers') | to_json }}"
  
  tasks:
    
#    - debug:
#        var: serversyses
#    - debug:
#        var: hostvars

    - name: 'Run Stress'
      # Command Line Docs: http://jmeter.apache.org/usermanual/get-started.html
      command: "{{ remote_jmeter_dir }}/bin/jmeter -n -X 
        -Dclient.rmi.localport={{ jmeter_client_rmi_local_port }} 
        -Dserver_port={{ jmeter_server_port }} 
        -t{{ remote_test_dir }}/jmeter-fhir-test.jmx 
        -l{{ remote_test_dir }}/log.jtl 
        -j{{ remote_test_dir }}/log-jmeter.txt 
        -R{{ jmeter_server_ip }} 
        -Jfhir_server={{ fhir_server }} 
        -Jthread_count={{ thread_count }} 
        -Jthread_loops={{ thread_loops }} 
        -Gcontinue_forever={{ continue_forever | bool | lower }} 
        -Gscheduler={{ scheduler | bool | lower }} 
        -Gduration={{ duration }}"
      #command: "/opt/fhir-stress/apache-jmeter-2.13/bin/jmeter --nongui --testfile /opt/fhir-stress/jmeter-fhir-test.jmx --logfile /opt/fhir-stress/log.jtl --jmeterlogfile /opt/fhir-stress/log-jmeter.txt --remotestart {{ hostvars | get_members(groups, 'servers') | map(attribute='ansible_fqdn') | list | join(',') }} --jmeterproperty fhir_server={{ fhir_server }}"

      # Added async and polling  because some servers will disconnect the ssh 
      # connection prior to test completion causing the ansible script to fail
      async: "{{ duration + (2*poll) }}" 
      poll: "{{ poll }}" 

    - name: Collect Results
      fetch: 
        src: "{{ remote_test_dir }}/log.jtl"
        dest: "results/"
        fail_on_missing: yes
        flat: yes
    
    - name: Collect Logs
      fetch: 
        src: "{{ remote_test_dir }}/log-jmeter.txt"
        dest: "results/"
        fail_on_missing: yes
        flat: yes
