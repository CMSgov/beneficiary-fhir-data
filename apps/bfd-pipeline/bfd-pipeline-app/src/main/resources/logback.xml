<configuration scan="false">
    <!-- Required to ensure that JUL respects log level changes. -->
    <contextListener class="ch.qos.logback.classic.jul.LevelChangePropagator"/>

    <!-- This appender will be sent all of the app's logging statements. -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{"yyyy-MM-dd'T'HH:mm:ss.SSSXXX", UTC} ${BFD_ENV_NAME} [%thread] %-5level %logger - %msg%n
            </pattern>
        </encoder>
    </appender>

    <!-- At 'debug', Hibernate will log SQL statements. -->
    <logger name="org.hibernate.SQL" level="debug"/>

    <!-- At 'debug', will display timing information about the idle task batches -->
    <logger name="gov.cms.bfd.pipeline.ccw.rif.load" level="info"/>

    <!-- At 'debug', a RIF file load will log the record counts for all tables. Do not do this in PROD, or TEST -->
    <logger name="gov.cms.bfd.pipeline.ccw.rif.load.RifLoader.recordCounts" level="info"/>

    <!-- At 'trace', Hibernate will log SQL parameter values. -->
    <logger name="org.hibernate.type" level="trace"/>

    <!-- Useful for debugging pipeline job issues if set to debug -->
    <logger name="gov.cms.bfd.pipeline.app.PipelineManager" level="info"/>
    <logger name="gov.cms.bfd.pipeline.app.PipelineJobRunner" level="info"/>
    <logger name="gov.cms.bfd.pipeline.ccw.rif.CcwRifLoadJob" level="info"/>
    <logger name="gov.cms.bfd.pipeline.sharedutils.jobs.store.PipelineJobRecordStore" level="info"/>
    <!-- Prevents some noisy nonsense running locally -->
    <logger name="software.amazon.awssdk.profiles.internal.ProfileFileReader" level="error"/>

    <!-- Configure the root logger to filter to 'info' and more severe, and
        send all events to 'STDOUT'. -->
    <root level="info">
        <appender-ref ref="STDOUT"/>
    </root>
</configuration>
