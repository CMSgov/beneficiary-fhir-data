# RDA Entity and Transformation DSL Spec

# Overview

RDA API data arrives in the form of protobuf message objects. These objects follow a set of conventions established by
the RDA API team when they write the proto files. Currently, we have hand-written java code to copy data from these
message objects into our own database entity objects. The code to perform this copying is embodied in
the `FissClaimTransformer` and `McsClaimTransformer` classes. Those classes use lower level classes to handle the
underlying idioms used by the RDA API. For example `EnumStringExtractor` knows how to map the contents of an enum field
to a string in our entities and `DataTransformer` knows how to copy and validate a variety of types of data such as
dates, strings, and enums.

We would like to develop a higher level abstraction to generate similar code from a higher level specification. This
specification would take the form of a declarative DSL based on some hierarchical data specification language such as
YAML or JSON. A code generator would process the DSL and use `javapoet` to generate java source code for both the JPA
entity classes and the transformer classes. The generated code would use the same low level classes as our hand-written
code.

# Strategy

Ideally the DSL would be a more succinct version of the code in the current transformers and would map easily into
classes and method calls. The DSL would benefit from conventions to simplify the structure of its code. The method calls
in `FissClaimTransformer` would be mapped to objects in the DSL. Additional properties would be defined in these objects
to specify the field names. Many things that have to be handled explicitly in java code could be handled by convention 
in the DSL processor.

When the processor runs it would create the following from each YAML file:

- JPA entity classes in the model module.
- SQL data definition file in model module.
- Transformer objects in the pipeline module.

Flyway migrations would still have to be created manually. The SQL data definition file produced by the processor could
be used as the basis for the migrations. This could involve copying the entire `CREATE TABLE`
statement for new tables or just copying individual column definitions for new columns added to existing tables.

## Sample Syntax

````yaml
# starts a new mapping from a protobuf message object to an entity object
mapping:
  # every mapping can have an id that is used to reference it from another mapping
  id: FissClaim
  # Full reference for the message class generated by protobuf compiler.
  # An object of this class is passed to the transformer generated by the DSL compiler.
  messageClassName: gov.cms.mpsm.rda.v1.FissClaimChange
  # Full reference for the entity class to be generated by DSL compiler.
  entityClassName: gov.cms.bfd.model.rda.PreAdjFissClaim
  # Full reference for the transformer class produced by the code generator.
  transformerClassName: gov.cms.bfd.pipeline.rda.grpc.source.FissClaimTransformer2
  table: 
    # Name of the table corresponding to the entity
    name: FissClaims
    # Name of the schema containing the table.
    # Defaults to public
    schema: pre_adj
    # Defines which fields (possibly only one) define the primary key for the table.
    primaryKeyFields:
      - dcn
    # Defines all of the columns in the entity.
    # Columns are defined independently of the fields/transformations so that multiple
    # transformations can reference the same column without duplicating any code.
    columns:
      - name: dcn
        # Defines the SQL column type.
        sqlType: varchar(23)
        # Optional boolean to define if column is nullable.
        # Defaults to true.
        nullable: false
      - name: sequenceNumber
        sqlType: bigint
        nullable: false
      - name: hicNo
        sqlType: varchar(12)
        nullable: false
      - name: currStatus
        sqlType: varchar(1)
        javaType: char
        nullable: false
      - name: currLoc1
        sqlType: varchar(1)
        # Optional java specific type for the property.
        # Defaults exist for each sqlType but this can override them.
        javaType: char
        nullable: false
      - name: currLoc2
        sqlType: varchar(5)
        nullable: false
      - name: totalChargeAmount
        sqlType: decimal(11,2)
      - name: receivedDate
        sqlType: date
      - name: mbi
        sqlType: varchar(13)
      - name: mbiHash
        sqlType: varchar(64)
  # The FissPayer message contains one of two possible sub-messages (InsuredPayer or BeneZParer).
  # These are mapped to a single set of columns and we add another column containing an enum value
  # that identifies which type of object was used to populate the record.
  # These enums are defined in the DSL and referenced by specific transformations.
  # Similarly FissClaim has a single column populated from one of 4 different enum fields.
  enumTypes:
    - name: ServTypeCdMapping
      values:
        - Normal
        - Clinic
        - SpecialFacility
        - Unrecognized
  # One or more fields definitions.
  # Each field is a mapping from some field in the message to a field in the entity.
  transformations:
    # Name of the message field from which to copy a value.
    # Names can use dot notation to reference properties of nested objects.
    # For example claim.currentStatus.
    - from: seq
      # Optional name of the column to store the mapped field.
      # Defaults to be the same as the last component of the from property.
      to: sequenceNumber
      # Defines attributes of the database column associated with this field
    - from: dcn
      column:
        sqlType: varchar(23)
        nullable: false
    - from: currStatus
      optional: false
      # The transformer property specifies what time of transformation to apply.
      # Defaults to one appropriate for the column type but can be overridden.
      # MessageEnum applies RDA API specific logic to map a protobuf enum to a string.
      transformer: MessageEnum
      # Some transformers accept key value pairs as configuration options.
      # The exact keys/value pairs to use depend on the transformer.
      transformerOptions:
        # Full reference to the protobuf enum class for this field.
        enumClass: gov.cms.mpsm.rda.v1.fiss.FissClaimStatus
        # This transformer can accept a comma separated list of special options.
        # In this case the extractor is told to flag any unrecognized enum string as an error.
        extractorOptions: RejectUnrecognized
    # Another enum based field but this one does not require any special extractorOptions.
    - from: currLoc1
      optional: false
      transformer: MessageEnum
      transformerOptions:
        enumClass: gov.cms.mpsm.rda.v1.fiss.FissProcessingType
    # Example of a field that can populate a column of the same name using default transformation.
    - from: mbi
    # Multiple transformations can be used for a single column to populate multiple columns.
    # In this case the IdHash transformer is used to populate mbiHash with a hashed version of the mbi field value.
    - from: mbi
      to: mbiHash
      transformer: IdHash
    # The servTypeCd value is set from one of 4 possible values in a oneof within the FissClaim.
    # For purposes of this sample just two are shown here.
    - from: servTypeCd
      # The MessageEnum transformer stores a value of an enum defined within this mapping
      # into a column if the field exists within the message.  The effect with oneof fields
      # like servTypeCd is to set the column to an enum matching which of the oneof fields
      # actually contained data in the message.
      transformer: MessageEnum
      transformerOptions:
        enumClass: gov.cms.mpsm.rda.v1.fiss.FissBillClassification
        hasUnrecognized: false
    - from: servTypeCdForClinics
      to: servTypeCd
      transformer: MessageEnum
      transformerOptions:
        enumClass: gov.cms.mpsm.rda.v1.fiss.FissBillClassificationForClinics
        hasUnrecognized: false
    # Some columns are populated with data from the transformer itself and don't map to any field in a message.
    # Placeholder names are defined in all upper case for those situations.  NOW just sets the value of the
    # column to be the timestamp for when the transformation was done.
    - from: NOW
      to: lastUpdated
  # Some RDA API messages contain "repeated" fields which are implemented in protobuf as arrays.
  # These are mapped to detail tables in the database schema.
  arrays:
    # the from property specifies the repeated field in the message
    - from: fissProcCodes
      # to specifies the name of the Set in the generated JPA entity.
      # JPA will bind entities in this set to records in the corresponding detail table.
      to: procCodes
      # Each array must have a mapping defined to specify how to transform the detail objects.
      mapping: FissProcCode
      # Used to build unique field names when reporting errors in detail objects.
      namePrefix: "procCode"
    - from: fissDiagCodes
      to: diagCodes
      mapping: FissDiagnosisCode
      namePrefix: "diagCode"
    - from: fissPayers
      to: payers
      mapping: FissPayer
      namePrefix: "payer"
````

The DSL would benefit from the following conventions:

- The `to` property for every field would only be necessary if it differed from the `from` property.
- The `nullable` property would default to `true` so it could be omitted for optional fields. Also the DSL processor
  would know that nullable fields would be optional in the incoming message field.
- The mapping of specific SQL types in the `type` property would tell the DSL which transformation to apply to the
  incoming string to convert it to the proper database type as well as which java type to use for the JPA entity object
  field.
- The conventions for how enum fields are mapped in messages by the RDA API would be known by the DSL processor so the
  values previously defined in an `EnumStringExtractor` constructor would be inferred by the DSL processor. It should be
  sufficient to specify the enum class and the field name of the enum field in the message.
- Mappings could be referenced from other mappings. For example a mapping would be specified for proc code messages from
  the RDA API and then that mapping would be referenced in the claim mapping's procCodes array. Alternatively we could
  nest the mappings but this might be harder to read for long data definitions.
- Arrays would have their primary key column and the `priority` column automatically populated by the DSL processor.

YAML can be somewhat wordy when compared to rows in a spreadsheet but it is also easier to edit, more flexible, and has
a hierarchical structure.

## Code Generation

The code generator could be defined as a maven plugin. The `pom.xml` would be configured to trigger the plugin during
the `generate-sources` lifecycle phase.

## TODO

This document is a work in progress. Here are a few of the things that it needs.

- How do we handle change objects? They will include a sequence number field and a field for the claim.  **Answer: The
  code generator would produce a transformer for each message to its database entity.  Changes have no corresponding
  entity and rarely ever change so the transformation of change objects would still be done by hand in a small amount 
  of code that delegates all of the other work to the generated transformer.**
