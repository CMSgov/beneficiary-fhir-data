# RDA Entity and Transformation DSL Spec

# Overview

RDA API data arrives in the form of protobuf message objects. These objects follow a set of conventions established by
the RDA API team when they write the proto files. Currently, we have hand-written java code to copy data from these
message objects into our own database entity objects. The code to perform this copying is embodied in
the `FissClaimTransformer` and `McsClaimTransformer` classes. Those classes use lower level classes to handle the
underlying idioms used by the RDA API. For example `EnumStringExtractor` knows how to map the contents of an enum field
to a string in our entities and `DataTransformer` knows how to copy and validate a variety of types of data such as
dates, strings, and enums.

We would like to develop a higher level abstraction to generate similar code from a higher level specification. This
specification would take the form of a declarative DSL based on some hierarchical data specification language such as
YAML or JSON. A code generator would process the DSL and use `javapoet` to generate java source code for both the JPA
entity classes and the transformer classes. The generated code would use the same low level classes as our hand-written
code.

# Strategy

Ideally the DSL would be a more succinct version of the code in the current transformers and would map easily into
classes and method calls. The DSL would benefit from conventions to simplify the structure of its code. The method calls
in `FissClaimTransformer` would be mapped to objects in the DSL. Additional properties would be defined in these objects
to specify the field names. Many things that have to be handled explicitly in java code could be added by convention in
the DSL processor.

When the processor runs it would create the following from each YAML file:

- JPA entity classes in the model module.
- SQL data definition file in model module.
- Transformer objects in the pipeline module.

Flyway migrations would still have to be created manually. The SQL data definition file produced by the processor could
be used as the basis for the migrations. This could involve copying the entire `CREATE TABLE`
statement for new tables or just copying individual column definitions for new columns in existing tables.

## Sample Syntax

````yaml
# defines starts a new mapping from a protobuf message object to an entity object
mapping:
  # every mapping can have an id that is used to reference it from another mapping
  id: FissClaim
  # Full reference for the message class generated by protobuf compiler.
  # An object of this class is passed to the transformer generated by the DSL compiler.
  message: gov.cms.mpsm.rda.v1.FissClaimChange
  # Full reference for the entity class to be generated by DSL compiler.
  entity: gov.cms.bfd.model.rda.PreAdjFissClaim
  table: 
    # Name of the table corresponding to the entity
    name: FissClaims
    # Name of the schema containing the table.
    # Defaults to public
    schema: pre_adj
    # Defines which fields (possibly only one) define the primary key for the table.
    primaryKeyFields:
      - dcn
  # One or more fields definitions.
  # Each field is a mapping from some field in the message to a field in the entity.
  fields:
    # Name of the message property from which to copy a value.
    # Names can use dot notation to reference properties of nested objects.
    # For example claim.currentStatus.
    - from: seq
      # Optional name of the property to store the mapped field.
      # Defaults to be the same as the from property.
      to: sequenceNumber
      # Defines attributes of the database column associated with this field
      column:
        # Defines the SQL column type.
        sqlType: bigint
        # Optional java specific type for the property.
        # Defaults exist for each sqlType but this can override them.
        javaType: long
        # Optional boolean to define if column is nullable.
        # Defaults to true.
        nullable: false
    - from: dcn
      column:
        sqlType: varchar(23)
        nullable: false
    # Uses a property from a claim object within the message
    - from: claim.currStatus
      column:
        sqlType: char(1)
        # Forces use of a char rather than a String
        javaType: char
        nullable: false
      # Details about protobuf enum associated with this property
      enum:
        # Full reference to the enum class generated by protobuf compiler
        class: gov.cms.mpsm.rda.v1.fiss.FissClaimStatus
        # Array of values to be treated as unsupported and generate an error.
        unsupported:
          - SomeEnumValueToReject
          - AnotherEnumValueToReject
        # Array of options used to control how the enum is handled by the transformer.
        options:
          - IgnoreUnrecognized
          - RejectUnrecognized 
    - from: claim.currLoc2
      column:
        sqlType: varchar(5)
        nullable: false
      enum: 
        class: gov.cms.mpsm.rda.v1.fiss.FissCurrentLocation2
    - from: claim.medaProvId
      column:
        sqlType: varchar(13)
    - from: claim.totalChargeAmount
      column:
        sqlType: decimal(11,2)
    # Since the sqlType is date the DSL processor knows to parse the message text as a date.
    - from: claim.recdDtCymd
      to: receivedDate
      column:
        sqlType: date
    # flag fields are class specific enums used to indicate how another field was populated
    # flag enum values are established by the fields that set them
    - flag: ServTypeCdMapping
      to: servTypeCdMapping
      column:
        sqlType: varchar(20)
    # sample fields that set a flag value to indicate which mapping populated a field
    - from: claim.servTypeCd
      type: varchar(1)
      enum: 
        class: gov.cms.mpsm.rda.v1.fiss.FissBillClassification
        options:
          - IgnoreUnrecognized
      # sets a value in the specified flag when a value is stored into this field
      flagged:
       name: ServTypeCdMapping
       value: Normal
    - from: claim.servTypeCdForClinics
      to: servTypeCd
      enum:
        class: gov.cms.mpsm.rda.v1.fiss.FissBillClassificationForClinics
        options:
          - IgnoreUnrecognized
      # sets a value in the specified flag when a value is stored into this field
      flagged:
        name: servTypeCd
        value: Clinic
    - from: claim.servTypeCdUnrecognized
      to: servTypeCd
      # sets a value in the specified flag when a value is stored into this field
      flagged:
        name: servTypeCdMapping
        value: Unrecognized
  # arrays defines how to map one-to-many relationships that are indicated by arrays in the incoming message.
  # Uses a reference to another mapping that defines how to handle the individual objects in the array.
  arrays:
    - from: claim.fissProcCodes
      to: procCodes
      mapping: FissProcCode
````

The DSL would benefit from the following conventions:

- The `to` property for every field would only be necessary if it differed from the `from` property.
- The `nullable` property would default to `true` so it could be omitted for optional fields. Also the DSL processor
  would know that nullable fields would be optional in the incoming message field.
- The mapping of specific SQL types in the `type` property would tell the DSL which transformation to apply to the
  incoming string to convert it to the proper database type as well as which java type to use for the JPA entity object
  field.
- The conventions for how enum fields are mapped in messages by the RDA API would be known by the DSL processor so the
  values previously defined in an `EnumStringExtractor` constructor would be inferred by the DSL processor. It should be
  sufficient to specify the enum class and the field name of the enum field in the message.
- Mappings could be referenced from other mappings. For example a mapping would be specified for proc code messages from
  the RDA API and then that mapping would be referenced in the claim mapping's procCodes array. Alternatively we could
  nest the mappings but this might be harder to read for long data definitions.
- Arrays would have their primary key column and the `priority` column automatically generated by the DSL processor.
- All tables will have a `lastUpdated` column in every record so no need to specify it in a mapping.

YAML can be somewhat wordy when compared to rows in a spreadsheet but it is also easier to edit, more flexible, and has
a hierarchical structure.

## Code Generation

The code generator could be defined as a maven plugin. The `pom.xml` would be configured to trigger the plugin during
the `generate-sources` lifecycle phase.

## TODO

This document is a work in progress. Here are a few of the things that it needs.

- How do we handle change objects? They will include a sequence number field and a field for the claim.  **Answer: Use
  the change object as the message and allow mappings to reference fields of nested objects. So `claim.currStatus` to
  pull the `currStatus` from the claim object within the change.**
- How do we actually use the generated code? Maybe it just implements an interface and we still have some logic in the
  caller (i.e. the `RdaSource`) to pass in whatever is needed.
- How do we ensure our plugin runs after the protobuf plugin? Or do we even need to? If we plan to do any reflection
  then we would want those classes to be in our classpath.
