# Utility Scripts

The scripts in this directory are intended to simplify building and running BFD on your local system.
The scripts are:

* `run-bfd-pipeline`: Runs the latest version of the BFD ETL pipeline in either RIF or RDA mode.
* `run-bfd-server`: Runs the latest version of the BFD FHIR server.
* `run-db-migrator`: Runs the latest version of the BFD database migrator.
* `run-rda-server`: Runs a mock RDA API server in one of several modes.
* `build-bfd`: Simplifies running maven to build BFD with a variety of options.
* `create-bfd-db`: Create a new postgresql 16 database running in a docker container.

# Dependencies

These scripts are intended to be as generic as possible while still accomplishing their task.
They have been developed and tested on a Macbook running Ventura.

* All of the scripts are written in `bash` and assume it is runnable as `/bin/bash`.
* Several of the scripts assume the presence of `lsof` in the user's PATH. This may not be available on linux or may use
  different command line options.
* Several of the scripts assume the presence of a `docker` command that can be run without sudo.
* Most of the scripts require the presence of a Java JDK version 17 or greater.
* Most of the scripts require the `BFD_PATH` and `BFD_EXEC` environment variables. See below for details on those.

# Run Scripts

## Overview

All of the run scripts operate in the same basic way. Each of them requires two environment variables
to be set in your local environment.

* `BFD_PATH`: The path to the BFD source repository. For example `$HOME/projects/beneficiary-fhir-data`.
* `BFD_EXEC`: The path to a directory that all of the run scripts can use to store files needed to run the programs.
  The `BFD_EXEC` directory should be a stand-alone, permanent directory outside of the BFD repository.
  For example `$HOME/bfd-exec`.

In addition the scripts assume they can find your maven artifact repository under `$HOME/.m2/repository` and your maven
build cache
under `$HOME/.m2/cache`.

Each of the run scripts will create an app specific working directory under `$BFD_EXEC`. The scripts all have the same
basic operating mode:

* Verify that `BFD_PATH` and `BFD_EXEC` are defined and that directories exist as expected.
* Process command line options to determine what settings to use when running the app.
* Determine whether or not localstack is running.
    * If it is all settings that can be will be copied into localstack SSM and the apps will run in SSM mode.
    * If it is not all settings will use environment variables.
* Determine if the user provided a docker image tag.
    * If one is provided the script will try to run the app as a docker container using an image previously generated by
      the jib maven plugin.
    * If one is not provided the script will run the app directly using the `java` executable in the user's `PATH`.
* Set up all of the settings the app will need when it runs.
* Install the app's runtime artifacts into the app's exec directory under `BFD_EXEC`.
* Launch the app.

## Common Features

### Help Option

All of the scripts accept a `-h` command line option that causes the script to print a quick
reference for its command line options and then exit.

### Debugging the Application

All of the scripts provide support for debugging the apps using an IDE in remote debugging mode.
The `-z` command line option runs the JVM with remote debugging enabled on port 5005.
The app will simply up normally and the debugger can connect to the app at any time.
When start-up logic in the app needs to be debugged the `-Z` option can be used instead.
It does the same thing but also configures the JVM to pause during startup and wait for a debugger to connect.

### Database Connections

Apps that connect to a database can be directed to postgresql running on any host and port.
The defaults are `localhost` and `5432`.
Use the `-d` option to use any other setting. The argument following this setting should be a
hostname and port separated by a `:`. If the port is omitted the 5432 is used as a default.
For example: `-d someplace.somewhere.org:2345` would connect to a postgresql database on
host `someplace.somewhere.org` on port 2345. To use that same host on the default port
simply use `-d someplace.somewhere.org`.

When an app runs in a docker container and needs to connect to a database that is also running in a docker
container, the host provided here should be the IP address of the container in the docker bridge network.
See the section on localstack below for instructions on how to find that IP address.

### S3 Mode

Apps that connect to S3 can be directed either to a local minio server or to AWS.
In addition they can also be directed to a specific bucket and directory within the bucket.
The three values, mode, bucket, and directory can be specified using the `-s` option
followed by the values separated by a `:`.

The mode argument must be either `minio` or `aws`.

For example: `-s minio:my-bucket:/test/directory`.

### Docker Containers

Apps that have jib generated docker images (not yet a standard feature in BFD) can be run as docker
containers. The scripts know the correct image name to use:

* `run-bfd-server` uses image `bfd-server-image`
* `run-bfd-pipeline` uses image `bfd-pipeline-app`
* `run-db-migrator` uses image `bfd-db-migrator`

To tell the script to use a container you need to provide the desired image tag (usually `latest`)
using the `-i` command line option. For example, `-i latest`.

Container mode does not support all possible settings (for example, remote debugging).
Once docker image support has become standard the scripts may be improved to support
the missing features.

### Localstack

Localstack can be used to run the apps using SSM configuration instead of environment variables.
This is especially important when running the apps in a container but works just as well when
running the apps directly in the JVM.

The scripts will auto-detect when localstack is running by checking port 4566 (the localstack port)
for a listener. If one is found all configuration settings will be stored in localstack
SSM instead of being provided in environment variables and the app will be executed with
the `SSM_REGION`, `SSM_ENDPOINT`, and `CONFIG_SETTINGS_JSON` environment variables set accordingly.

Because of the complexities of docker networking the app will not be able to find a localstack
service using `localhost`. Instead it needs to use an IP address on the docker bridge network.
This IP address can be provided to the app using the `-l` command line option.

The correct IP to use can be found using this docker command: `docker network inspect bridge`.

On a Macbook running Docker Desktop the output of the command might contain something like this:

```
... other stuff ...
        "Containers": {
            "--hex id--": {
                "Name": "localstack_main",
                "EndpointID": "--hex id--",
                "MacAddress": "02:42:ac:11:00:03",
                "IPv4Address": "172.17.0.3/16",
                "IPv6Address": ""
            },
            "--hex id--": {
                "Name": "bfd-db",
                "EndpointID": "--hex id--",
                "MacAddress": "02:42:ac:11:00:02",
                "IPv4Address": "172.17.0.2/16",
                "IPv6Address": ""
            }
        },
... other stuff ...
```

In this example the localstack container is named `localstack_main` and its bridge network IP address is `172.17.0.3`.
To allow a docker container to communicate with localstack you would need to add the command line option `-l 172.17.0.3`
when running the app.

### Quick Start

This option is almost never needed but is available for the rare case when it might be useful.
The `-x` option tells the script to run the app from artifacts already present in the exec directory.
Basically, it skips the installation step. It will fail if the artifacts are not present.
The only situation where this might be useful is when you are making changes that would prevent
the app from compiling but want to run a previous version of it to test something else.
For example, maybe you can't compile the mock RDA server at the moment but can compile the pipeline app
and need to test it against a previous version of the mock RDA server.

## Running BFD DB Migrator

Use this script to initialize a newly created database.
For example, every time you run `bfd-db` script to create a new database you must
then run `run-db-migrator` to set up the schema within that new database.

To run the DB migrator you must first have a database for it to connect to.
Assuming that database is listening on localhost, port 5432 (for example the database created by `bfd-db`),
you can run the `run-db-migrator` script with no command line options.

The app will run directory in the JVM and log all output to stdout.
When the script runs it will print a bunch of output indicating that zip files are being extracted.
Check the output to determine if the app ran successfully.

All command line options for `run-db-migrator` are described in the overview section of this document.

```
$ ./utils/scripts/run-db-migrator -h
Runs BFD database migrator.  Use command line options to change behaviors.

run-db-migrator [options]
-d db_host[:db_port]  Name of database host.  Optional :n uses port n.
-i image_tag          Runs the migrator as a containing using the image with given tag.
-l localstack_ip      Localstack IP address (for bridge networking).
-x                    Do not install latest version before running.
-z                    Enable debugger support but start immediately.
-Z                    Enable debugger support and wait for debugger to connect.
-h                    Prints this help message.

Option defaults:
  -d localhost:5432
```

## Running BFD Server

To run the BFD FHIR server you must first have a database for it to connect to.
Assuming that database is listening on localhost, port 5432 (for example the database created by `bfd-db`),
you can run the `run-bfd-server` script with no command line options.

The server will run directly in the JVM and log all output to stdout. When the script runs it will print
a bunch of output indicating that zip files are being extracted. Then it will start the server and print the server's
log output. Check the output for any exception messages. The most likely failure will be caused by the server
being unable to connect to a database.

All command line options for `run-bfd-server` are described in the overview section of this document.

```
$ ./utils/scripts/run-bfd-server -h
Runs a BFD server.  Use command line options to change behaviors.

run-bfd-server [options]
-d db_host[:db_port]      Name of database host.  Optional :n uses port n.
-i image_tag              Runs the server as a containing using the image with given tag.
-l localstack_ip          Localstack IP address (for bridge networking).
-x                        Do not install latest version before running.
-z                        Enable debugger support but start immediately.
-Z                        Enable debugger support and wait for debugger to connect.
-h                        Prints this help message.

Option defaults:
  -d localhost:5432
```

## Running ETL Pipeline

The ETL pipeline app is the most complex to run.
It supports many more configuration settings than either the server or the migrator.
In addition to all of the standard options the pipeline also accepts ones specific to either
the RDA or RIF pipeline as well as a mode indicating which pipeline (RIF or RDA) jobs to execute.

### Modes

The pipeline can run in one of four modes. The mode is a required positional argument
provided after any command line options. Possible values for mode are:

* `rif`: Just run the `CcwRifLoadJob` job.
* `random`: Run the `RdaFissClaimLoadJob` and `RdaMcsClaimLoadJob` jobs plus the `RdaServerJob` job configured to serve
  random data.
* `s3`: Run the `RdaFissClaimLoadJob` and `RdaMcsClaimLoadJob` jobs plus the `RdaServerJob` job configured to serve data
  from an S3 bucket.
* `rda`: Run the `RdaFissClaimLoadJob` and `RdaMcsClaimLoadJob` jobs configured to call a remote RDA API server for
  data.

### Command Line Options

The pipeline app supports all of the standard options plus several unique to itself:

```
$ ./utils/scripts/run-bfd-pipeline -h
run-bfd-pipeline [options] run_mode
-b batch_size             Number of entities per batch.
-c cache_size             Size of hicn/mbi cache.
-d db_host[:db_port]      Name of database host.  Optional :n uses port n.
-i image_tag              Runs the pipeline as a container using the image with given tag.
-I                        Enable RIF idempotency mode.
-l localstack_ip          Localstack IP address (for bridge networking).
-r run_interval           Job execution interval in seconds.
-R host:port:token        Host name, port, and token to call RDA API remote server.
-s mode:bucket:directory  S3 mode (minio or aws), bucket and directory.
-t threads                Number of threads for RIF/RDA jobs.
-x                        Do not install latest version before running.
-z                        Enable debugger support but start immediately.
-Z                        Enable debugger support and wait for debugger to connect.
-h                        Prints this help message.

Supported long options:

--bene-load-options threads:batch_size:queue_multiple
  Sets the RifLoader settings to use for beneficiary data.

--claim-load-options threads:batch_size:queue_multiple
  Sets the RifLoader settings to use for claim data.

Run mode options: 
  rif     RIF pipeline only.
  random  RDA pipeline only.  Using in-process random API server.
  s3      RDA pipeline only.  Using in-process S3 API server.
  rda     RDA pipeline only.  Using remote RDA API server with host/port/token from command line.

Option defaults:
  -b 20
  -c 100
  -d localhost:5432
  -l localhost
  -r 60
  -R localhost:5003:
  -s minio:bfd-pipeline:test
  -t 20
```

The non-standard options are:

| Option                 | Argument                          | Description                                                                         | Config Setting                                                                             |
|------------------------|-----------------------------------|-------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|
| `-b`                   | batch_size                        | Used to set the batch size used by the pipeline job.                                | `RIF_JOB_BATCH_SIZE`, `RDA_JOB_BATCH_SIZE`                                                 |
| `-c`                   | cache_size                        | Used to set the number of entries in the HICN/MBI cache.                            | `HICN_HASH_CACHE_SIZE`                                                                     |
| `-I`                   |                                   | Sets RIF pipeline to idempotent mode.                                               | `IDEMPOTENCY_REQUIRED`                                                                     |
| `-r`                   | run_interval                      | Sets the job schedule/interval in seconds for RDA jobs.                             | `RDA_JOB_INTERVAL_SECONDS`                                                                 |
| `-R`                   | host:port:token                   | Sets the hostname, port, and auth token used to connect to a remote RDA API server. | `RDA_GRPC_HOST`, `RDA_GRPC_PORT`, `RDA_GRPC_AUTH_TOKEN`                                    |
| `-t`                   | threads                           | Number of writer threads used by jobs.                                              | `LOADER_THREADS`, `RDA_JOB_WRITE_THREADS`                                                  |
| `--bene-load-options`  | threads:batch_size:queue_multiple | Sets beneficiary specific settings for RIF pipeline                                 | `LOADER_THREADS`,  `RIF_JOB_BATCH_SIZE`, `RIF_JOB_QUEUE_SIZE_MULTIPLE`                     |
| `--claim-load-options` | threads:batch_size:queue_multiple | Sets claim specific settings for RIF pipeline                                       | `LOADER_THREADS_CLAIMS`, `RIF_JOB_BATCH_SIZE_CLAIMS`, `RIF_JOB_QUEUE_SIZE_MULTIPLE_CLAIMS` |

## Running Mock RDA API Server

The RDA API server app supports a few custom command line options.
More information about the server can be found in the README.md file in the `bfd-pipeline-rda-grpc-apps` project in the
BFD repo.
It can serve partially adjudicated claims data from several sources:

* Randomly generated data that intended to provide bulk data for load testing but is not realistic.
* Data from NDJSON files stored in an S3 bucket intended to serve more realistic data from Synthea using files generated
  by the RDA Bridge app.

The mode used is based on the command line options used when running the script.  
Random data is served unless the `-s` option is provided to specify an S3 bucket and directory to use.

### Command Line Options

The RDA Server app supports some of the standard options plus several unique to itself:

```
$ ./utils/scripts/run-rda-server -h
Runs mock RDA API server.  Use command line options to change behaviors.

run-rda-server [options] [-r max_records]
-e error_rate                   Randomly make 1/error_rate claims invalid.
-r max_records                  Maximum number of records to return to client.
-s mode:bucket:directory:cache  S3 mode (minio or aws), bucket and directory.
-x                              Do not install latest version before running.
-z                              Enable debugger support but start immediately.
-Z                              Enable debugger support and wait for debugger to connect.
-h                              Prints this help message.

Option defaults:
  -e 0
  -r 25000
  -s minio:::
```

The non-standard options are:

| Option | Argument                      | Description                                                                                                                     |
|--------|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------|
| `-e`   | `error_rate`                  | The error rate is the number of good claims per transformation error.                                                           |
| `-r`   | `max_records`                 | The maximum number of records to return to the client.  Useful to scale out data served to clients over multiple pipeline runs. |
| `-s`   | `mode:bucket:directory:cache` | All of the S3 settings.  See below for more explanation.                                                                        |

### Error Rate

The error rate is useful to test the RDA pipeline's ability to recover from transformation errors.
When this option is present the server will randomly insert transformation errors into a fraction of claims equal to the
one per whatever the argument value is.
For example `-e 5000` would tell the server to insert an error `1/5000 == 0.02%` of the time.
With this and a fast interval in the pipeline it is easy to test the DLQ and retry logic of the pipeline's FISS and MCS
claim jobs.

### S3 Settings

Using the `-s` setting causes the server to look for NDJSON files in an S3 bucket instead of generating random claims.
The argument consists of four parts separated by `:`

* mode: Either `minio` or `aws`.
* bucket: The bucket containing the files.
* directory: The directory within the bucket containing the files.
* cache: If specified this must be a directory to be used for caching files locally.

If the cache setting can be left empty the server will create a temporary directory and delete it when the server exits.
If the cache setting is specified the server will use that directory on disk to store cached files permanently.

# Database Creation Script

The `create-bfd-db` script can be used to quickly create a docker container and volume to use as a database for local
testing.
Every time the script runs it creates a brand new container and volume.
Both are given the name `bfd-db`.

When you create a new database it will not have the schema yet.
You must run the migrator to set up the schema before you can use the database with BFD server or pipeline.

If you just want to reuse the same database you can simply restart the container rather than running this script.

When the script runs it first deletes any existing volume or container with the name `bfd-db`.
Then it starts a new container using the `postgres:16` image.
The image is always pulled so each run will use the latest available image from docker hub.

After starting the container it waits for port 5432 to have a listener.
Finally it uses the `createdb` command to create the `fhirdb` database.

There may be some scary output during the wait for the port to open.
The message `Cannot assign requested address.` is harmless as long as the script proceeds past it.

If all steps are successful the message `Database created successfully.` will be printed and the script will exit.

## Conflict with Local Postgresql

There is an issue with Docker Desktop on a Mac.  If you have a native postgresql running on your
mac it will quietly shadow the docker container.  Any attempt to connect to postgresql will
ignore the container and instead will connect to your native postgresql.

The usual manifestation of this would look like this:

```
$ psql -h localhost -U bfd -d fhirdb
psql: error: connection to server at "localhost" (::1), port 5432 failed: FATAL:  role "bfd" does not exist
```

The same sort of error can appear in logs when you try to run the pipeline or bfd server.

To determine if this is happening, see if there is a native postgresql process running on your mac.
For example, if you installed postgresql using homebrew you could use this command to see if it is running:

```
$ brew services -v
Name          Status  User              File
emacs         none                      
postgresql@14 started yourusername ~/Library/LaunchAgents/homebrew.mxcl.postgresql@14.plist
unbound       none         
```

In this example you can see that the database is running.  Stop the database to resolve the issue:

```
$ brew services stop postgresql
Warning: Formula postgresql was renamed to postgresql@14.
Stopping `postgresql@14`... (might take a while)
==> Successfully stopped `postgresql@14` (label: homebrew.mxcl.postgresql@14)
```

With the native database stopped, the docker container should start to receive incoming connections:

```
$ psql -h localhost -U bfd -d fhirdb
Password for user bfd: 
psql (14.8 (Homebrew))
Type "help" for help.

fhirdb=# 
```

# Bootstrapping RDA Pipeline Testing

Example flow for starting with a clean database and populating it with 10,000 random
partially adjudicated claims using the mock RDA API server.

In one terminal window/tab do the following commands:

```
$ cd ...your BFD repo /apps directory...
$ ./utils/scripts/build-bfd
$ ./utils/scripts/create-bfd-db
$ ./utils/scripts/run-db-migrator
```

At this point you should have a docker container named `bfd-db` running and that database will contain an empty schema.

Now start a second terminal window/tab and run the following commands:

```
$ cd ...your BFD repo /apps directory...
$ ./utils/scripts/run-rda-server -r 1000
```

Now that window has a running mock RDA API server configured to serve up to 1,000 random claims to each client.

Now go back to the first window and run the following commands:

```
./utils/scripts/run-bfd-pipeline -r 3 -t 5 rda
```

At this point the first window should have a running pipeline app set to connect to the local mock RDA API server and
ingest all claims using 5 threads.
After a while the jobs should run and ingest the 1,000 claims.
Once they have been ingested the jobs will stop running and then run again on a 3 second interval.

For extra credit you can see how the jobs handle the addition of new data.

Go back to the second window (the one running RDA server).
Use `Control-C` to kill the server.
Then reset it with a higher claim limit.

```
$ ./utils/scripts/run-rda-server -r 2000
```

Go back to the first window again and you should see the pipeline jobs recognize the newly available claims and process
them.
