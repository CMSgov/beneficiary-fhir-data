---

##
# Ensures that an ELB load balancer exists for the FHIR servers. If a new FHIR 
# server master AMI is available, it will rollout that AMI to the ELB via its
# auto-scaling group.
##

- name: Provision/Update ELB for FHIR Servers
  hosts: localhost
  connection: local
  gather_facts: false

  tasks:

    - name: 'Create New EC2 Launch Config for FHIR Servers'
      ec2_lc:
        name: "bluebutton-backend-fhir-servers-{{ deploy_id }}"
        image_id: "{{ ami_backend_fhir_master.image_id }}"
        instance_type: "{{ ec2_backend_fhir_instance_type }}"
        key_name: "{{ ec2_key_name }}"
        instance_profile_name: 'BlueButtonBackend-EC2Services'
        region: "{{ aws_region }}"
        assign_public_ip: true
        security_groups:
          - "{{ ec2_group_default_id }}"
          - "{{ ec2_group_ssh_all_id }}"
          - "{{ ec2_group_backend_fhir_internal_id }}"
        instance_monitoring: true

    - name: 'Create EC2 Load Balancer (ELB) for Backend'
      ec2_elb_lb:
        name: 'bluebutton-backend'
        state: 'present'
        connection_draining_timeout: 300
        idle_timeout: 60
        # Note: This might be specific to the sandbox; production may use an 
        # internal-only ELB, balancing requests coming from an internal VPN 
        # gateway.
        scheme: 'internet-facing'
        region: "{{ aws_region }}"
        cross_az_load_balancing: false
        zones:
          - "{{ aws_zone }}"
        security_group_ids:
          - "{{ ec2_group_default_id }}"
          - "{{ ec2_group_backend_fhir_external_id }}"
        listeners:
          - protocol: 'tcp'
            load_balancer_port: "{{ backend_fhir_port_external }}"
            instance_port: "{{ backend_fhir_port_internal }}"
        health_check:
          ping_protocol: tcp
          ping_port: "{{ backend_fhir_port_internal }}"
          response_timeout: 5
          interval: 7
          unhealthy_threshold: 2
          healthy_threshold: 2
        #access_logs:
        #  interval: 5 # minutes (default is 60)
        #  s3_location: "{{ s3_bucket_deployment }}"
        #  s3_prefix: 'elb-access-logs/bluebutton-backend'
        wait: true
      register: ec2_elb_lb_backend

    - name: 'Create/Update Route 53 Record for Load Balancer'
      route53:
        command: 'create'
        overwrite: 'true'
        zone: "{{ backend_domain }}"
        record: 'fhir.{{ backend_domain }}.'
        type: 'CNAME'
        ttl: 3600
        value: "{{ ec2_elb_lb_backend.elb.dns_name }}"
        wait: true

    - name: 'Set Variable for Target Number of FHIR Servers'
      set_fact:
        ec2_asg_backend_fhir_target_count: 1

    - name: 'Create/Update EC2 Auto-Scaling Group for FHIR Servers'
      ec2_asg:
        name: 'bluebutton-backend-fhir-servers'
        load_balancers: 'bluebutton-backend'
        launch_config_name: "bluebutton-backend-fhir-servers-{{ deploy_id }}"
        health_check_type: 'EC2'
        min_size: "{{ ec2_asg_backend_fhir_target_count }}"
        desired_capacity: "{{ ec2_asg_backend_fhir_target_count }}"
        max_size: 10
        replace_all_instances: true
        replace_batch_size: 1
        region: "{{ aws_region }}"
        availability_zones:
          - "{{ aws_zone }}"
        vpc_zone_identifier:
          - "{{ aws_subnet }}"
        tags:
          - Name: bluebutton-backend-fhir-autoscaled
          - Application: "{{ ec2_tag_application }}"
          - CreatedBy: "{{ whoami.stdout }}"
        wait_for_instances: true
      # The delay-retry-until approach used here was taken from these two references:
      # * https://github.com/ansible/ansible-modules-core/issues/2652
      # * https://github.com/ansible/immutablish-deploys/blob/master/roles/rolling_asg/tasks/main.yml
      register: ec2_asg_backend_fhir
      until: (ec2_asg_backend_fhir is defined) and ((ec2_asg_backend_fhir.viable_instances | int) >= (ec2_asg_backend_fhir_target_count | int))
      delay: 10
      retries: 120

