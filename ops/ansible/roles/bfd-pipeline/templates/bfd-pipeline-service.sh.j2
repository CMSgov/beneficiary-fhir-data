#!/bin/bash

export S3_BUCKET_NAME='{{ data_pipeline_s3_bucket }}'
export HICN_HASH_ITERATIONS='{{ data_pipeline_hicn_hash_iterations }}'  # The minimum number of iterations recommended by NIST is 1000.
export HICN_HASH_PEPPER='{{ data_pipeline_hicn_hash_pepper }}'
export DATABASE_URL='{{ data_pipeline_db_url }}'
export DATABASE_USERNAME='{{ data_pipeline_db_username }}'
export DATABASE_PASSWORD='{{ data_pipeline_db_password }}'
export LOADER_THREADS='{{ data_pipeline_loader_threads }}'
export IDEMPOTENCY_REQUIRED='{{ data_pipeline_idempotency_required }}'
export NEW_RELIC_METRIC_HOST='{{ data_pipeline_new_relic_metric_host }}'
export NEW_RELIC_METRIC_PATH='{{ data_pipeline_new_relic_metric_path }}'
{% if data_pipeline_new_relic_app_name is defined %}
export NEW_RELIC_APP_NAME='{{ data_pipeline_new_relic_app_name }}'
{% else %}
#export NEW_RELIC_APP_NAME=
{% endif %}
{% if data_pipeline_new_relic_metric_key is defined %}
export NEW_RELIC_METRIC_KEY='{{ data_pipeline_new_relic_metric_key }}'
{% else %}
#export NEW_RELIC_METRIC_KEY=
{% endif %}
export RDA_JOB_ENABLED='{{ data_pipeline_rda_job_enabled }}'
export RDA_JOB_INTERVAL_SECONDS='{{ data_pipeline_rda_job_interval_seconds }}'
export RDA_JOB_BATCH_SIZE='{{ data_pipeline_rda_job_batch_size }}'
{% if data_pipeline_rda_job_starting_fiss_seq_num is defined %}
export RDA_JOB_STARTING_FISS_SEQ_NUM='{{ data_pipeline_rda_job_starting_fiss_seq_num }}'
{% endif %}
{% if data_pipeline_rda_job_starting_mcs_seq_num is defined %}
export RDA_JOB_STARTING_MCS_SEQ_NUM='{{ data_pipeline_rda_job_starting_mcs_seq_num }}'
{% endif %}
export RDA_GRPC_HOST='{{ data_pipeline_rda_grpc_host }}'
export RDA_GRPC_PORT='{{ data_pipeline_rda_grpc_port }}'
export RDA_GRPC_MAX_IDLE_SECONDS='{{ data_pipeline_rda_grpc_max_idle_seconds }}'
export RDA_GRPC_AUTH_TOKEN='{{ data_pipeline_rda_grpc_auth_token }}'
export RDA_GRPC_SERVER_TYPE='{{ data_pipeline_rda_grpc_server_type }}'
export RDA_GRPC_INPROC_SERVER_MODE='{{ data_pipeline_rda_grpc_inproc_server_mode }}'
export RDA_GRPC_INPROC_SERVER_S3_REGION='{{ data_pipeline_rda_grpc_inproc_server_s3_region }}'
export RDA_GRPC_INPROC_SERVER_S3_BUCKET='{{ data_pipeline_rda_grpc_inproc_server_s3_bucket }}'
export RDA_GRPC_INPROC_SERVER_S3_DIRECTORY='{{ data_pipeline_rda_grpc_inproc_server_s3_directory }}'

# Referenced by the pipeline's logback.xml file to add environment name for use in splunk.
export BFD_ENV_NAME='{{ env_name_std }}'

# Either don't set this variable, or set it to one of: BENEFICIARY, CARRIER, DME, HHA, HOSPICE, INPATIENT, OUTPATIENT, PDE, SNF
# export DATA_SET_TYPE_ALLOWED="BENEFICIARY"

exec "{{ data_pipeline_dir }}/bfd-pipeline-app-1.0.0-SNAPSHOT/bfd-pipeline-app.sh" \
	-Djava.io.tmpdir={{ data_pipeline_tmp_dir }} \
	&>> "{{ data_pipeline_dir }}/bluebutton-data-pipeline.log"
