#!/bin/bash

export CCW_RIF_JOB_ENABLED='{{ data_pipeline_ccw_rif_job_enabled }}'
export S3_BUCKET_NAME='{{ data_pipeline_s3_bucket }}'
export HICN_HASH_ITERATIONS='{{ data_pipeline_hicn_hash_iterations }}'  # The minimum number of iterations recommended by NIST is 1000.
export HICN_HASH_PEPPER='{{ data_pipeline_hicn_hash_pepper }}'
export DATABASE_URL='{{ data_pipeline_db_url }}'
export DATABASE_USERNAME='{{ data_pipeline_db_username }}'
export DATABASE_PASSWORD='{{ data_pipeline_db_password }}'
# NOTE: RIF Loader Threads are generally some multiple of available cpus/core, e.g. `$((3 * $(nproc)))`
export LOADER_THREADS='{{ ansible_processor_vcpus * (rif_thread_multiple | int) }}'
export RIF_JOB_BATCH_SIZE='{{ rif_job_batch_size }}'
export RIF_JOB_QUEUE_SIZE_MULTIPLE='{{ rif_job_queue_size_multiple }}'
export LOADER_THREADS_CLAIMS='{{ ansible_processor_vcpus * (rif_thread_multiple_claims | int) }}'
export RIF_JOB_BATCH_SIZE_CLAIMS='{{ rif_job_batch_size_claims }}'
export RIF_JOB_QUEUE_SIZE_MULTIPLE_CLAIMS='{{ rif_job_queue_size_multiple_claims }}'

export IDEMPOTENCY_REQUIRED='{{ data_pipeline_idempotency_required }}'

# Observability
{% if data_pipeline_micrometer_cw_enabled is defined and data_pipeline_micrometer_cw_namespace is defined %}
export MICROMETER_CW_ENABLED={{ data_pipeline_micrometer_cw_enabled }}
export MICROMETER_CW_NAMESPACE={{ data_pipeline_micrometer_cw_namespace }}
export MICROMETER_CW_INTERVAL={{ data_pipeline_micrometer_cw_interval | default('PT1M') }}
{% else %}
# export MICROMETER_CW_ENABLED=
# export MICROMETER_CW_NAMESPACE=
# export MICROMETER_CW_INTERVAL=
{% endif %}

export NEW_RELIC_METRIC_HOST='{{ data_pipeline_new_relic_metric_host }}'
export NEW_RELIC_METRIC_PATH='{{ data_pipeline_new_relic_metric_path }}'
{% if data_pipeline_new_relic_app_name is defined %}
export NEW_RELIC_APP_NAME='{{ data_pipeline_new_relic_app_name }}'
{% else %}
#export NEW_RELIC_APP_NAME=
{% endif %}
{% if data_pipeline_new_relic_metric_key is defined %}
export NEW_RELIC_METRIC_KEY='{{ data_pipeline_new_relic_metric_key }}'
{% else %}
#export NEW_RELIC_METRIC_KEY=
{% endif %}

export RDA_JOB_ENABLED='{{ data_pipeline_rda_job_enabled }}'
export RDA_JOB_INTERVAL_SECONDS='{{ data_pipeline_rda_job_interval_seconds }}'
export RDA_JOB_BATCH_SIZE='{{ data_pipeline_rda_job_batch_size }}'
export RDA_JOB_WRITE_THREADS='{{ data_pipeline_rda_job_write_threads }}'
{% if data_pipeline_rda_process_dlq is defined %}
export RDA_JOB_PROCESS_DLQ='{{ data_pipeline_rda_process_dlq }}'
{% endif %}
{% if data_pipeline_rda_version is defined %}
export RDA_JOB_RDA_VERSION='{{ data_pipeline_rda_version }}'
{% endif %}
{% if data_pipeline_rda_job_starting_fiss_seq_num is defined %}
export RDA_JOB_STARTING_FISS_SEQ_NUM='{{ data_pipeline_rda_job_starting_fiss_seq_num }}'
{% endif %}
{% if data_pipeline_rda_job_starting_mcs_seq_num is defined %}
export RDA_JOB_STARTING_MCS_SEQ_NUM='{{ data_pipeline_rda_job_starting_mcs_seq_num }}'
{% endif %}
export RDA_GRPC_HOST='{{ data_pipeline_rda_grpc_host }}'
export RDA_GRPC_PORT='{{ data_pipeline_rda_grpc_port }}'
export RDA_GRPC_MAX_IDLE_SECONDS='{{ data_pipeline_rda_grpc_max_idle_seconds }}'
export RDA_GRPC_AUTH_TOKEN='{{ data_pipeline_rda_grpc_auth_token }}'
export RDA_GRPC_SERVER_TYPE='{{ data_pipeline_rda_grpc_server_type }}'
export RDA_GRPC_INPROC_SERVER_MODE='{{ data_pipeline_rda_grpc_inproc_server_mode }}'
export RDA_GRPC_INPROC_SERVER_S3_REGION='{{ data_pipeline_rda_grpc_inproc_server_s3_region }}'
export RDA_GRPC_INPROC_SERVER_S3_BUCKET='{{ data_pipeline_rda_grpc_inproc_server_s3_bucket }}'
export RDA_GRPC_INPROC_SERVER_S3_DIRECTORY='{{ data_pipeline_rda_grpc_inproc_server_s3_directory }}'

# Referenced by the pipeline's logback.xml file to add environment name for use in splunk.
export BFD_ENV_NAME='{{ env_name_std }}'


# Either don't set this variable, or set it to one of: BENEFICIARY, CARRIER, DME, HHA, HOSPICE, INPATIENT, OUTPATIENT, PDE, SNF
# export DATA_SET_TYPE_ALLOWED="BENEFICIARY"

# Set some additional variables.
JVM_ARGS='{{ data_pipeline_jvm_args }}'
SERVICE_SCRIPT="$(find {{ data_pipeline_dir }} -type f -name bfd-pipeline-app.sh)"

exec "$SERVICE_SCRIPT" \
	${JVM_ARGS} \
	-Djava.io.tmpdir={{ data_pipeline_tmp_dir }} -Dorg.jboss.logging.provider=slf4j \
	&>> "{{ data_pipeline_dir }}/bluebutton-data-pipeline.log"
