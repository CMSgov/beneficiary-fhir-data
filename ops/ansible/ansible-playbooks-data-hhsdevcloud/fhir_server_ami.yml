---

##
# Provisions a single FHIR server in EC2, configures it correctly, creates an
# AMI of it, then tears down the EC2 instance.
# 
# It is expected that later plays will use the resulting EC2 AMI in an auto-
# scaling group.
##

- name: Provision FHIR Server Master
  hosts: localhost
  connection: local
  gather_facts: false

  tasks:

    - name: Provision FHIR Server Master
      ec2:
        key_name: "{{ ec2_key_name }}"
        group:
          - default
          - ssh-all
        instance_type: "{{ ec2_backend_fhir_instance_type }}"
        image: "{{ ami_id_rhel_7_encrypted }}"
        region: "{{ aws_region }}"
        zone: "{{ aws_zone }}"
        vpc_subnet_id: "{{ aws_vpc_subnet }}"
        volumes:
          - device_name: /dev/sda1
            volume_type: gp2
            # The logs occasionally filled up the drive when it was only 10GB.
            volume_size: 40
        instance_profile_name: BlueButtonBackend-DataServer
        wait: true
        exact_count: 1
        count_tag:
          Name: bluebutton-backend-fhir-master
        instance_tags:
          Name: bluebutton-backend-fhir-master
          Application: "{{ ec2_tag_application }}"
          CreatedBy: "{{ whoami.stdout }}"
      register: ec2_backend_fhir_master
    
    - name: Add FHIR Server to Inventory (transient)
      add_host:
        name: backend_fhir_master
        ansible_user: "{{ ssh_user_rhel }}"
        ansible_host: "{{ ec2_backend_fhir_master.instances[0].public_dns_name }}"
    
    - name: Wait for SSH
      wait_for:
        host: "{{ item.public_dns_name }}"
        port: 22
        search_regex: OpenSSH
        state: started
        # This delay seems to be necessary for newly-provisioned instances.
        # SSH will be up but it's not immediately configured to accept the SSH 
        # key.
        delay: 30
        timeout: 320
      with_flattened:
        - "{{ ec2_backend_fhir_master.instances }}"

- name: Configure RHEL for Ansible Pipelining
  hosts: backend_fhir_master
  vars:
    ansible_ssh_pipelining: false
  roles:
    - rhel_ansible_pipelining

- name: Configure Blue Button Data Server
  hosts: backend_fhir_master
  tasks:
    - name: Apply Blue Button Data Server Role
      include_role:
        name: karlmdavis.bluebutton_data_server
      vars:
        data_server_artifacts_mode: local
        data_server_appserver_installer_name: "wildfly-dist-{{ wildfly_version }}.tar.gz"
        data_server_appserver_name: "wildfly-{{ wildfly_version }}"
        data_server_appserver_local_dir: "{{ maven_repo }}/org/wildfly/wildfly-dist/{{ wildfly_version }}"
        data_server_appserver_https_port: "{{ backend_fhir_port_internal }}"
        data_server_war_name: "bfd-server-war-{{ bluebutton_server_version }}.war"
        data_server_war_local_dir: "{{ maven_repo }}/gov/cms/bfd/bfd-server-war/{{ bluebutton_server_version }}"
        data_server_ssl_server_genkeypair_args: "-keyalg RSA -keysize 4096 -dname cn=*.fhir.{{ backend_domain }} -ext san=dns:fhir.{{ backend_domain }} -validity 3650"
        data_server_ssl_client_cas:
          - alias: bluebutton_frontend_ca
            certificate: "{{ lookup('file', 'files/data_server_client_frontend_ca.pem') }}"
        data_server_ssl_client_certificates:
          - alias: client_test
            certificate: "{{ lookup('file', 'files/client-test-certificate.pem') }}"
        data_server_db_url: "jdbc:postgresql://{{ hostvars['localhost']['backend_postgres_endpoint'] }}:{{ hostvars['localhost']['backend_postgres_port'] }}/{{ backend_db_name }}"
        data_server_db_username: "{{ backend_postgres_master_username }}"
        data_server_db_password: "{{ backend_postgres_master_password }}"
        #data_server_db_max_connections: (see group_vars/all/main.yml)

- name: Configure AWS CloudWatch Logs Agent
  hosts: backend_fhir_master
  become: true
  roles:
    - role: singleplatform-eng.awslogs
      # FIXME It'd be cleaner for this to be applied via another `include_role` task above, but that's broken as of Ansible 2.3.2.0: https://github.com/ansible/ansible/issues/29159
      awslogs_config:
        - file: /usr/local/bluebutton-data-server/bluebutton-server-app.log
          datetime_format: '%Y-%m-%d %H:%M:%S,%f'
          initial_position: 'start_of_file'
          log_group_name: 'bluebutton-sandbox-backend/data-server/bluebutton-data-server-app.log'
          log_stream_name: '{instance_id}'
          buffer_duration: 5000
        - file: "/usr/local/bluebutton-data-server/wildfly-{{ wildfly_version }}/standalone/log/access.log"
          datetime_format: '%d/%b/%Y:%H:%M:%S %z'
          initial_position: 'start_of_file'
          log_group_name: 'bluebutton-sandbox-backend/data-server/access.log'
          log_stream_name: '{instance_id}'
          buffer_duration: 5000

- name: Configure CloudWatch Metrics
  hosts: localhost
  connection: local
  gather_facts: false

  tasks:

    - name: Create Filter Pattern Variable
      set_fact:
        filterPatternBase: '[remote_host_name, remote_logical_username, remote_authenticated_user, timestamp, timestamp_zone, request, query_string, status_code, bytes, duration_milliseconds, original_query_id, original_query_counter, original_query_timestamp, developer, developer_name, application_id, application, user_id, user, beneficiary_id]'

    - name: Set Metric Filter for Counting All Requests
      command: >
        aws logs put-metric-filter
        --log-group-name bluebutton-sandbox-backend/data-server/access.log
        --filter-name "{{ item.name }}"
        --filter-pattern "{{ item.filterPattern }}"
        --metric-transformations "metricName={{ item.name }},metricNamespace=bluebutton-sandbox-backend,metricValue={{ item.metricValue }}{{ '' if item.defaultValue == "" else ',defaultValue={0}'.format(item.defaultValue) }}"
      with_items:
        - { name: 'bluebutton-sandbox-backend/data-server/http-requests/count', metricValue: '1', defaultValue: '0',
            filterPattern: "{{ filterPatternBase }}" }
        - { name: 'bluebutton-sandbox-backend/data-server/http-requests/count/not-http-2xx', metricValue: '1', defaultValue: '0',
            filterPattern: "{{ filterPatternBase | regex_replace('status_code', 'status_code != 2*') }}" }
        - { name: 'bluebutton-sandbox-backend/data-server/http-requests/latency', metricValue: '$duration_milliseconds', defaultValue: '',
            filterPattern: "{{ filterPatternBase }}" }
        - { name: 'bluebutton-sandbox-backend/data-server/http-requests/latency/patient', metricValue: '$duration_milliseconds', defaultValue: '',
            filterPattern: "{{ filterPatternBase | regex_replace('request', 'request = *Patient*') }}" }
        - { name: 'bluebutton-sandbox-backend/data-server/http-requests/latency/coverage', metricValue: '$duration_milliseconds', defaultValue: '',
            filterPattern: "{{ filterPatternBase | regex_replace('request', 'request = *Coverage*') }}" }
        - { name: 'bluebutton-sandbox-backend/data-server/http-requests/latency/eob', metricValue: '$duration_milliseconds', defaultValue: '',
            filterPattern: "{{ filterPatternBase | regex_replace('request', 'request = *ExplanationOfBenefit*') }}" }

- name: Convert FHIR Server Master to AMI
  hosts: localhost
  connection: local
  gather_facts: false

  tasks:

    - name: Create AMI from FHIR Server Master
      ec2_ami:
        instance_id: "{{ ec2_backend_fhir_master.instance_ids[0] }}"
        region: "{{ aws_region }}"
        wait: true
        name: "bluebutton-backend-fhir-{{ deploy_id }}"
        tags:
          Name: "bluebutton-backend-fhir-{{ deploy_id }}"
          Application: "{{ ec2_tag_application }}"
          CreatedBy: "{{ whoami.stdout }}"
      register: ami_backend_fhir_master
    - debug: 
        msg: "Created FHIR Server Master AMI: {{ ami_backend_fhir_master | to_json }}"

    - name: Terminate FHIR Server Master
      ec2:
        state: 'absent'
        instance_ids: "{{ ec2_backend_fhir_master.instance_ids }}"
        region: "{{ aws_region }}"
      ignore_errors: true
