#!/usr/bin/env groovy

properties([
  parameters([
    string(name: 'NUM_BENES', defaultValue: '10000',
      description: 'The number of synthetic beneficiaries to generate'),

    string(name: 'NUM_FUTURE_MONTHS', defaultValue: '0',
      description: 'The number of months into the future that claim lines should be '
      + 'generated. If specified, future claims will be split in the '
      + 'generated output to allow for proper loading'),

    booleanParam(name: 'USE_TARGET_CONTRACT', defaultValue: false,
      description: 'If checked, use the below contract partD contract number for all generated items.'),

    string(name: 'TARGET_CONTRACT', defaultValue: 'Y9999',
      description: 'If USE_TARGET_CONTRACT is checked, indicates a single part D contract that all generated claims'
      + ' will be associated with.'),

    booleanParam(name: 'UPDATE_END_STATE_S3', defaultValue: true,
      description: 'Specifies whether the main end_state.properties stored in the synthea S3 '
      + 'bucket should be updated with the end_state.properties '
      + 'of this run. If false, the main end_state.properties is left as-is. '
      + 'If true, the main end_state.properties is replaced. Regardless of this '
      + 'parameter\'s value, the starting and final end_state.properties will '
      + 'be available in the generated output directory uploaded to S3')
  ])
])

pipeline {
  agent {
    kubernetes {
      defaultContainer 'docker'
      yaml """
apiVersion: v1
kind: Pod
spec:
  serviceAccount: bfd
  volumes:
  - name: docker-socket
    emptyDir: {}
  containers:
  - name: docker
    image: docker:20.10-git
    command:
    - sleep
    args:
    - 99d
    volumeMounts:
    - name: docker-socket
      mountPath: /var/run
    tty: true
  - name: docker-daemon
    image: docker:20.10-dind
    securityContext:
      privileged: true
    volumeMounts:
    - name: docker-socket
      mountPath: /var/run
    resources:
      limits:
        memory: 16384Mi
        cpu: 8000m
      requests:
        memory: 16384Mi
        cpu: 8000m
"""
    }
  }


  options {
    // Nothing within this repository is required for running this pipeline, so skipping the default
    // checkout saves us some time
    skipDefaultCheckout()
    buildDiscarder(logRotator(numToKeepStr: '15', daysToKeepStr: '30'))
  }

  stages {
    // The way this pipeline is configured is not ideal. It would be more appropriate to use the
    // bfd-mgmt-synthea-generation container as the agent for the subsequent stages, but due to
    // lacking options for authenticating to a private ECR (no access to kubectl, no Amazon ECR
    // plugin, etc.) prior to defining an agent stage using docker-in-docker is the next-best
    // option
    // TODO: Refactor this to _not_ use DinD but instead use the synthea image as the agent, when possible

    stage('Install prerequisites') {
      steps {
        sh 'apk add --no-cache aws-cli bash jq'

        // Address limitations resulting from CVE-2022-24767
        sh 'git config --global --add safe.directory "$WORKSPACE"'
      }
    }

    stage('Pull bfd-mgmt-synthea-generation') {
      steps {
        script {
          awsAuth.assumeRole()

          registryId = sh(
            returnStdout: true,
            script: "aws ecr describe-registry --region \"${env.AWS_REGION}\" | jq -r '.registryId'"
          ).trim()
          privateRegistryUri = "${registryId}.dkr.ecr.${env.AWS_REGION}.amazonaws.com"
          imageName = "${privateRegistryUri}/bfd-mgmt-synthea-generation:latest"

          sh "aws ecr get-login-password --region \"${env.AWS_REGION}\" | docker login --username AWS --password-stdin \"${privateRegistryUri}\""
          sh "docker pull \"${imageName}\""
        }
      }
    }

    stage('Retrieve end_state.properties') {
      steps {
        echo 'Pulling the latest end_state.properties from the bfd-mgmt-synthea bucket'

        script {
          awsAuth.assumeRole()
        }
        sh "aws s3 cp \"s3://bfd-mgmt-synthea/end_state/end_state.properties\" ."
      }
    }

    stage('Generate Synthea Data') {
      steps {
          sh ("docker run -v /var/run/docker.sock:/var/run/docker.sock "
              + "-v \"\$(pwd)\"/end_state.properties:/usr/local/synthea/end_state.properties:ro "
              + "-v \"\$(pwd)\"/out:/usr/local/synthea/out "
              + "\"${imageName}\" "
              + "-n \"${params.NUM_BENES}\" "
              + "-f \"${params.NUM_FUTURE_MONTHS}\" "
              + "-u \"${params.USE_TARGET_CONTRACT}\" "
              + "-r \"${params.TARGET_CONTRACT}\"")
      }
    }

    stage('Upload Synthea Data') {
      steps {
        echo 'Uploading generated output to bfd-mgmt-synthea bucket...'

        script {
          awsAuth.assumeRole()
        }
        sh "aws s3 cp \"\$(pwd)/out/\" \"s3://bfd-mgmt-synthea/generated\" --recursive"
      }
    }

    stage('Update Old end_state.properties') {
      when {
        expression {
          return params.UPDATE_END_STATE_S3
        }
      }
      steps {
        echo 'Replacing the old end_state.properties in the bfd-mgmt-synthea bucket...'

        script {
          awsAuth.assumeRole()

          // The generated output is placed within a folder with a timestamp in its name, so 
          // the path to the end_state.properties is different each time. We use the find command
          // to find the full path of the final end_state.properties in out/ regardless of the
          // generated directory's name
          def endStateProperties = sh(
            returnStdout: true,
            script: 'find "$(pwd)"/out -name end_state.properties -type f'
          ).trim()
          sh "aws s3 cp \"${endStateProperties}\" \"s3://bfd-mgmt-synthea/end_state/end_state.properties\""
        }
      }
    }
  }
}
