 properties([
   parameters([
     string(name: 'env', description: 'The BFD Environment to run the BFD Pipeline out-of-band in'),
     choice(name: 'pipeline_variant',
       // TODO: Update with RDA when possible
       choices: ['ccw'],
       description: 'The variant of BFD Pipeline to run out-of-band'
     ),
     string(name: 'timeout_minutes',
       defaultValue: '60',
       description: 'The timeout, in minutes, that this Jenkins Pipeline will wait until '
                   + 'automatically scaling-in the out-of-band BFD Pipeline instance'
     ),
     booleanParam(name: 'lock_environment_resource', defaultValue: true,
       description: 'Whether or not the corresponding environment resource is locked while this '
                   + 'Jenkins Pipeline is running. Setting this to false will allow for '
                   + 'deployments and other potentially destructive actions to occur while the OOB '
                   + 'BFD Pipeline is running'
     ),
     booleanParam(name: 'suspend_scheduled_actions', defaultValue: true,
       description: 'Whether or not AutoScaling Scheduled Actions will be suspended on the BFD '
                   + 'Pipeline AutoScaling Group. If this is false (toggled off), ASG Scheduled '
                   + 'Actions created by the BFD Pipeline Scheduler will execute and could '
                   + 'potentially destroy the Pipeline created by this Jenkins Pipeline'
     )
  ])
])

pipeline {
  agent {
    kubernetes {
      defaultContainer 'bfd-cbc-build'
      yaml """
apiVersion: v1
kind: Pod
spec:
  serviceAccount: bfd
  restartPolicy: Never
  containers:
    - name: bfd-cbc-build
      image: "public.ecr.aws/c2o1d8s9/bfd-cbc-build:jdk21-mvn3-tfenv3-kt1.9-latest" # TODO: consider a smarter solution for resolving this image
      command:
        - cat
      tty: true
      imagePullPolicy: IfNotPresent
"""
    }
  }
  options {
        buildDiscarder(logRotator(numToKeepStr: '15', daysToKeepStr: '30'))
  }

  options {
    // This is an unfortunate hack that allows for toggling environment-locked builds of this
    // pipeline by locking either the environment-level lock respected by all pipelines that mutate
    // the environment or just a random GUID that is unique to this invocation of this pipeline. The
    // hack is necessary as code within the options block must only be Pipeline Steps (Groovy script
    // is not allowed) thus necessitating nested ternary conditionals
    lock resource: params.lock_environment_resource ? (params.env.trim() == 'prod-sbx'
                                                        ? 'env_prod_sbx'
                                                        : "env_${params.env.trim()}")
                                                    : "bfd-run-pipeline-oob-${UUID.randomUUID()}"
  }

  stages {
    stage('Scale-out BFD Pipeline Instance') {
      steps {
        script {
          trimmedEnv = params.env.trim()
          autoScalingGroupName = "bfd-${trimmedEnv}-pipeline-${params.pipeline_variant}"
          if (params.suspend_scheduled_actions) {
            echo "Suspending scheduled actions on ASG ${autoScalingGroupName}"

            awsAuth.assumeRole()
            withEnv(["asgName=${autoScalingGroupName}"]) {
              suspendResult = sh(
                returnStatus: true,
                script: '''
aws autoscaling suspend-processes \
  --auto-scaling-group-name $asgName \
  --scaling-processes ScheduledActions
'''
              )
            }

            if (suspendResult != 0) {
              error ("Could not suspend ASG ${autoScalingGroupName}'s Scheduled Actions; non-zero "
                     + "exit code ${suspendResult}")
            }
          }

          echo "Setting Desired Capacity on ${autoScalingGroupName} to 1"
          awsAuth.assumeRole()
          withEnv(["asgName=${autoScalingGroupName}"]) {
            setDesiredCapacityResult = sh(
              returnStatus: true,
              script: '''
aws autoscaling set-desired-capacity --auto-scaling-group-name $asgName --desired-capacity 1
'''
            )
          }

          if (setDesiredCapacityResult != 0) {
            error ("Could not set desired capacity to 1 on ${autoScalingGroupName}; non-zero exit "
                   + "code ${setDesiredCapacityResult}")
          }
        }
      }
    }

    stage('BFD Pipeline Instance Running...') {
      steps {
        script {
          echo ("The BFD ${params.pipeline_variant} Pipeline Instance should now be running "
                + "out-of-band; the requested scaled-out instance's details can be viewed in the "
                + "AWS Console: "
                + "https://us-east-1.console.aws.amazon.com/ec2/v2/home?region=us-east-1#AutoScalingGroupDetails:id=${autoScalingGroupName};view=instanceManagement")

          def pipelineTimeout = params.timeout_minutes.trim().toInteger()
          try {
            timeout(time: pipelineTimeout, unit: 'MINUTES') {
              input ("Once the static ${params.pipeline_variant} pipeline instance is no longer "
                     + "needed, click either Abort or Proceed to cleanup")
            }
          } catch(err) {}
        }
      }
    }
  }

  post {
    cleanup {
      script {
        if (params.suspend_scheduled_actions) {
          echo "Resuming scheduled actions on ASG ${autoScalingGroupName}"

          awsAuth.assumeRole()
          withEnv(["asgName=${autoScalingGroupName}"]) {
            resumeResult = sh(
              returnStatus: true,
              script: '''
aws autoscaling resume-processes \
--auto-scaling-group-name $asgName \
--scaling-processes ScheduledActions
'''
            )
          }

          if (resumeResult != 0) {
            error ("Could not resume ASG ${autoScalingGroupName}'s Scheduled Actions; non-zero "
                    + "exit code ${resumeResult}")
          }
        }

        echo "Setting Desired Capacity on ${autoScalingGroupName} to 0"
        awsAuth.assumeRole()
        withEnv(["asgName=${autoScalingGroupName}"]) {
          setDesiredCapacityResult = sh(
            returnStatus: true,
            script: '''
aws autoscaling set-desired-capacity --auto-scaling-group-name $asgName --desired-capacity 0
'''
          )
        }

        if (setDesiredCapacityResult != 0) {
          error ("Could not set desired capacity to 0 on ${autoScalingGroupName}; non-zero exit "
                  + "code ${setDesiredCapacityResult}")
        }
      }
    }
  }
}
